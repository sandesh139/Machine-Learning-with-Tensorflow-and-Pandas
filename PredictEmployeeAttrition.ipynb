{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First import necessary modules for the project\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import Markdown, display\n",
    "import matplotlib.pyplot as plt\n",
    "# Make numpy values easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"WA_Fn-UseC_-HR-Employee-Attrition.csv\", sep = ',')\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting idea of the range of monthly income.\n",
    "attritionAndIncome = data[['Attrition', 'MonthlyIncome']].sort_values(by=['MonthlyIncome'])\n",
    "\n",
    "#number of bins is chosen to be 29\n",
    "attritionAndIncome['binning'] = pd.cut(attritionAndIncome['MonthlyIncome'], bins=29)\n",
    "attritionAndIncome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OnlyYesIncome = attritionAndIncome[attritionAndIncome[\"Attrition\"].str.match('Yes')]\n",
    "yesIncomeSorted= OnlyYesIncome.groupby(by =['binning']).size().reset_index()\n",
    "OnlyNoIncome = attritionAndIncome[attritionAndIncome[\"Attrition\"].str.match('No')]\n",
    "NoIncomeSorted= OnlyNoIncome.groupby(by =['binning']).size().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newDataIncome = pd.merge(yesIncomeSorted, NoIncomeSorted, on = 'binning').rename(columns={\"0_x\": \"Yes\", \"0_y\":\"No\"})\n",
    "newDataIncome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRatioYN(row):\n",
    "    return row['Yes']/ row['No']\n",
    "newDataIncome['Yes_No_Ratio'] = newDataIncome.apply(getRatioYN, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "    \n",
    "printmd('Lower the yes_no_ratio lower the attrition is. So, employee with very lowest salary has the highest attrition')\n",
    "newDataIncome.sort_values(by = 'Yes_No_Ratio')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newDataIncome.plot(x = \"binning\", y = \"Yes_No_Ratio\")\n",
    "frame1 = plt.gca()\n",
    "frame1.axes.get_xaxis().set_visible(False)\n",
    "\n",
    "plt.xlabel('Incomes')\n",
    "plt.ylabel('Yes_No_Ratio')\n",
    "plt.suptitle('Employee attrition vs monthly income', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attritionAndDistance = data[['Attrition', 'DistanceFromHome']].sort_values(by=['DistanceFromHome'])\n",
    "attritionAndDistance['binning'] = pd.cut(attritionAndDistance['DistanceFromHome'], bins=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OnlyYes = attritionAndDistance[attritionAndDistance[\"Attrition\"].str.match('Yes')]\n",
    "yesSorted= OnlyYes.groupby(by =['binning']).size().reset_index()\n",
    "OnlyNo = attritionAndDistance[attritionAndDistance[\"Attrition\"].str.match('No')]\n",
    "noSorted = OnlyNo.groupby(by =['binning']).size().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newDataDistance = pd.merge(yesSorted, noSorted, on = 'binning').rename(columns={\"0_x\": \"Yes\", \"0_y\":\"No\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRatio(row):\n",
    "    return row['No']/ row['Yes']\n",
    "newDataDistance['No_Yes_Ratio'] = newDataDistance.apply(getRatio, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printmd('This shows higher the ratio, lower the attrition is. We can see the close distance once has the lower attrition. Also, the mean distances has higher attrition')\n",
    "newDataDistance.sort_values(by = 'No_Yes_Ratio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newDataDistance.plot(x = \"binning\", y = \"No_Yes_Ratio\")\n",
    "frame1 = plt.gca()\n",
    "frame1.axes.get_xaxis().set_visible(False)\n",
    "\n",
    "plt.suptitle('Employee attrition vs distance', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the csv file and change the Attrition from Yes or No to 0 or 1 and split the data for train and test purpose\n",
    "\n",
    "data = pd.read_csv(\"WA_Fn-UseC_-HR-Employee-Attrition.csv\", sep = ',')\n",
    "data['Attrition'] = data['Attrition'].map({'Yes':0 ,'No':1})\n",
    "train, test = train_test_split(data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train.copy()\n",
    "train_labels = train_features.pop('Attrition')\n",
    "\n",
    "test_features = test.copy()\n",
    "test_labels = test_features.pop('Attrition')\n",
    "# Create a symbolic input\n",
    "input = tf.keras.Input(shape=(), dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {}\n",
    "\n",
    "for name, column in train_features.items():\n",
    "    dtype = column.dtype\n",
    "    if dtype == object:\n",
    "        dtype = tf.string\n",
    "    else:\n",
    "        dtype = tf.float32\n",
    "    inputs[name] = tf.keras.Input(shape=(1,), name=name, dtype=dtype)\n",
    "\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_inputs = {name:input for name,input in inputs.items()\n",
    "                  if input.dtype==tf.float32}\n",
    "\n",
    "x = layers.Concatenate()(list(numeric_inputs.values()))\n",
    "norm = preprocessing.Normalization()\n",
    "norm.adapt(np.array(train[numeric_inputs.keys()]))\n",
    "all_numeric_inputs = norm(x)\n",
    "\n",
    "all_numeric_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_inputs = [all_numeric_inputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, input in inputs.items():\n",
    "    if input.dtype == tf.float32:\n",
    "        continue\n",
    "    lookup = preprocessing.StringLookup(vocabulary=np.unique(train_features[name]))\n",
    "    one_hot = preprocessing.CategoryEncoding(max_tokens=lookup.vocab_size())\n",
    "    x = lookup(input)\n",
    "    x = one_hot(x)\n",
    "    preprocessed_inputs.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_inputs_cat = layers.Concatenate()(preprocessed_inputs)\n",
    "train_preprocessing = tf.keras.Model(inputs, preprocessed_inputs_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_dict = {name: np.array(value) for name, value in train_features.items()}\n",
    "test_features_dict = {name: np.array(value) for name, value in test_features.items()}\n",
    "features_dict = {name:values[:1] for name, values in train_features_dict.items()}\n",
    "train_preprocessing(features_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_model(preprocessing_head, inputs):\n",
    "    body = tf.keras.Sequential([\n",
    "        layers.Dense(64),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    preprocessed_inputs = preprocessing_head(inputs)\n",
    "    result = body(preprocessed_inputs)\n",
    "    model = tf.keras.Model(inputs, result)\n",
    "    model.compile(loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
    "                optimizer=tf.optimizers.Adam(), metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "data_model = data_model(train_preprocessing, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model.fit(x=train_features_dict, y=train_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluate on test data\")\n",
    "loss, accuracy= data_model.evaluate(test_features_dict, test_labels)\n",
    "print(\"test loss :\", loss)\n",
    "print(\"test accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here Positive number denotes \n",
    "print(\"Predict on test data\")\n",
    "x = data_model.predict(test_features_dict)\n",
    "x[40:70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels[40:70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
